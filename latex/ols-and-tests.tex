\section{Metoda najmniejszych kwadratów (MNK)}\label{sec:mnk}

\subsection{Opis}\label{subsec:opis}
Metoda najmniejszych kwadratów służy do estymacji parametrów w modelu ekonometrycznym.

\[ \alpha = (X^{T}X)^{-1}X^{T}y \]

\subsection{Założenia MNK}\label{subsec:założenia-mnk}

\begin{itemize}
    \item Zmienne objaśniające są nielosowe i nieskorelowane ze składnikiem losowym
    \item \[E(\varepsilon) = 0\]
    \item \[Var(\varepsilon) = \sigma^2 \iota\]
    \item \[rank(X) = (k+1) <n\]
\end{itemize}

\subsection{Twierdzenie Gaussa-Markowa}\label{subsec:twierdzenie-gaussa-markowa}
Przy spełnieniu założeń MNK estymator jest BLUE
\begin{itemize}
    \item \textbf{B}est
    \item \textbf{L}inear
    \item \textbf{U}nbiased
    \item \textbf{E}stimator
\end{itemize}

\section {Poprawnośc statystyczna modelu}\label{sec:testy-statystyczne-modelu}

\subsection{Występowanie efektu katalizy}\label{subsec:występowanie-efektu-katalizy}

Mówimy, że w modelu ekonometrycznym określonym przez regularną
parę korelacyjną (R, \(R_0\)) występuje efekt katalizy, jeżeli istnieje taka
para wskaźników (i, j), dla której

\begin{equation}
    r_{ij} < 0 \; lub \; r_{ij}  > \frac{r_i}{r_j}
\end{equation}

Nateżenie efektu katalizy mierzymy wzorem

\[ \eta = R^2 - H \]

Gdzie H oznacza integralną pojemność informacyjną zmiennych objaśniających.

\subsection{Koincydentność}\label{subsec:koincydentność}

Mowimy, że zmienna jest koincydentna, jeżeli:

\begin{equation}
    sgn(r_1) = sign(a_i)
\end{equation}

Koincydencja jest zjawiskiem porządanym w modelu.

\subsection{Istotność współczynnika determinacji}\label{subsec:istotność-współczynnika-determinacji}

Test ten pozwala sprawdzić istotność wszystkich zmiennych w modelu naraz.

\begin{equation}
    \begin{split}
        &H_0: \alpha_1 = \alpha_2 = \dots = \alpha_k = 0 \\
        &H_1: \alpha_1 \ne 0 \; lub \; \alpha_2 \ne 0 \; lub \; \dots \; lub \; \alpha_k \ne 0
    \end{split}
\end{equation}

Statystyka F-Snedachora ma postać \(F = \frac{R^2}{k} \frac{n-k-1}{1-R^2}\) o \(r_1 = k\) i \(r_2 = n-k-1\) stopniach swobody.
Jeżeli \(F > F_\alpha,r1,r2 \) to odrzucamy \(H_0\).
Oznacza to, że przynajmniej jedna zmienna objaśniająca jest statystycznie ważna w modelu.

\subsection{Normalność reszt}\label{subsec:normalność-reszt}

Jednym z założeń MNK jest normalność reszt.

\subsubsection{Test Jarque-Bera}
Test Jarque-Bera polega na obliczeniu skośności oraz kurtozy w modelu i porównanie ich do znanym wartości z rozkładu normalnego

\begin{equation}
    \begin{split}
        &H_0: \varepsilon \sim N(0,\sigma) \\
        &H_1: \varepsilon \not\sim N(0,\sigma)
    \end{split}
\end{equation}

Statystyke testową wyznaczamy ze wzoru:

\begin{equation}
    JB = n (\frac{1}{6}B_1 + \frac{1}{24}(B_2 -3)^2)
\end{equation}

Gdzie:

\begin{equation}
    \begin{split}
        &\bar{S} = \sqrt{\frac{1}{n}\sum_{t=1}^{n}e^2_t} \\
        &\sqrt{B_1} = \frac{1}{n\bar{S^3}\sum_{t=1}^{n}e^3_t}  \\
        & B_2 = \frac{1}{n\bar{S^4}\sum_{t=1}^{n}{e^4_t}}
    \end{split}
\end{equation}

Statystyka JB ma rozklad \(\chi^2\) z dwoma stopniami swobody.

Jeżeli \(JB > \chi^2_2\) to odrzucamy \(H_0\).

\subsubsection{Centralne twierdzenie graniczne}

Jeżeli próbę z populacji o sredniej \(\mu\) i skończinym odchyleniu standardowym \(\sigma \), to rozkład sredniej z próby, \(\bar{X}\), daży do rozkładu normalnego o sredniej \(\mu\) i odchyleniu standardowym \(\sqrt{\sigma} \), gdy liczebnosć próby wzrasta nieograniczenie, czyli dla "dostatecznie dużych" n.

\begin{equation}
    \begin{split}
        \frac{\frac{1}{n} \sum_{i=1}^{n} X_i - \mu}{\frac{\sigma}{\sqrt{n}}}
    \end{split}
\end{equation}

W moim modelu występuje około 20 tysięcy obserwacji, więc przy sprawdzaniu normalności rozkładu można powołać się na to twierdzenie.

\subsection{Istotność statystyczna pojedyńczych zmiennych objaśniających}\label{subsec:istotność-statystyczna-zmiennych-objaśniających}
Jeżeli spełnione jest założenie o normalności reszt, to możemy postawić następujące hipotezę

\begin{equation}
    \begin{split}
        &H_0: \alpha_j = 0 \\
        &H_1: \alpha_j \ne 0
    \end{split}
\end{equation}

Statystyka t ma postać \(t = \frac{\alpha j}{S_{\alpha j}}\).
Jeżeli \(|t| > t_{n -(k+1)}\) to odrzucamy \(H_0\).
Oznacza to brak wplywu zmiennej \(X_j\) na Y.

\subsection{Liniowość modelu - test liczby serii}\label{subsec:liniowość-modelu---test-liczby-serii}

\begin{equation}
    \begin{split}
        &H_0: postać \; modelu \; jest \; liniowa \\
        &H_1: postać \; modelu \; nie \; jest \; liniowa
    \end{split}
\end{equation}

Reszty modelu należy ułożyć wzgledem posortowanej rosnąco zmiennej objaśnianej, a następnie policzyć dla nich ilość serii.
Pod pojęciem serii rozumiemy każdy ciąg elementów o identycznych znakach.

\begin{equation}
    \begin{split}
        &\mu = \frac{2N_+ N_-}{N} +1 \\
        &\sigma^2 = \frac{(\mu -1)(\mu-2)}{N-1} \\
        &Z = \frac{R - \mu}{\sigma}
    \end{split}
\end{equation}


Gdzie

\begin{equation}
    \begin{split}
        &N_+ - ilość dodatnich elementów \\
        &N_- - ilość ujemnych elementów \\
        &N - ilość elementów \\
        &R - ilość serii \\
    \end{split}
\end{equation}


Jeżeli \(|Z| > Z_{1-\alpha/2}\) to odrzucamy \(H_0\).